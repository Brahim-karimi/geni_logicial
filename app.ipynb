{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4711ca5-a128-43bf-b71c-f1c61d8709f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "from PyQt5.QtCore import QTimer, Qt\n",
    "from PyQt5.QtGui import QImage, QPixmap, QFont\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QHBoxLayout, QPushButton, QWidget, QFrame\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "\n",
    "# Charger le modèle de classification\n",
    "processor = AutoImageProcessor.from_pretrained(\"dima806/asl_alphabet_image_detection\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"dima806/asl_alphabet_image_detection\")\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"Convertit un cadre de la caméra en image PIL et le prétraite pour la classification\"\"\"\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "    inputs = processor(images=pil_image, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "def classify_asl_frame(frame):\n",
    "    \"\"\"Classifie un cadre pour détecter la lettre en langage des signes\"\"\"\n",
    "    inputs = preprocess_frame(frame)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    predicted_label = model.config.id2label[predicted_class_idx]\n",
    "    confidence = torch.softmax(logits, dim=-1)[0][predicted_class_idx].item()\n",
    "    return predicted_label, confidence * 100\n",
    "\n",
    "class ASLApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Configuration de la fenêtre\n",
    "        self.setWindowTitle(\"Détection de la Langue des Signes\")\n",
    "        self.setGeometry(100, 100, 900, 700)\n",
    "        self.setStyleSheet(\"background-color: #1a1a1a; color: white;\")\n",
    "\n",
    "        # Layout principal\n",
    "        self.layout = QVBoxLayout()\n",
    "\n",
    "        # Titre\n",
    "        self.title_label = QLabel(\"D\\u00e9tection de la Langue des Signes\")\n",
    "        self.title_label.setAlignment(Qt.AlignCenter)\n",
    "        self.title_label.setFont(QFont(\"Arial\", 24, QFont.Bold))\n",
    "        self.title_label.setStyleSheet(\"color: white;\")\n",
    "        self.layout.addWidget(self.title_label)\n",
    "\n",
    "        # Layout pour la vidéo et les résultats\n",
    "        self.video_layout = QHBoxLayout()\n",
    "\n",
    "        # Affichage de la vidéo\n",
    "        self.video_label = QLabel()\n",
    "        self.video_label.setAlignment(Qt.AlignCenter)\n",
    "        self.video_label.setStyleSheet(\"background-color: #333;\")\n",
    "        self.video_layout.addWidget(self.video_label)\n",
    "\n",
    "        # Résultats\n",
    "        self.result_frame = QFrame()\n",
    "        self.result_frame.setStyleSheet(\"background-color: #2e2e2e; border: 1px solid #555;\")\n",
    "        self.result_layout = QVBoxLayout()\n",
    "\n",
    "        self.character_label = QLabel(\"Caract\\u00e8re :\")\n",
    "        self.character_label.setFont(QFont(\"Arial\", 18))\n",
    "        self.character_label.setAlignment(Qt.AlignCenter)\n",
    "        self.character_label.setStyleSheet(\"color: white;\")\n",
    "        self.result_layout.addWidget(self.character_label)\n",
    "\n",
    "        self.word_label = QLabel(\"Mot :\")\n",
    "        self.word_label.setFont(QFont(\"Arial\", 18))\n",
    "        self.word_label.setAlignment(Qt.AlignCenter)\n",
    "        self.word_label.setStyleSheet(\"color: white;\")\n",
    "        self.result_layout.addWidget(self.word_label)\n",
    "\n",
    "        self.result_frame.setLayout(self.result_layout)\n",
    "        self.video_layout.addWidget(self.result_frame)\n",
    "\n",
    "        self.layout.addLayout(self.video_layout)\n",
    "\n",
    "        # Boutons de contrôle\n",
    "        self.buttons_layout = QHBoxLayout()\n",
    "\n",
    "        self.start_button = QPushButton(\"D\\u00e9marrer\")\n",
    "        self.start_button.setStyleSheet(\"background-color: #007bff; color: white;\")\n",
    "        self.start_button.clicked.connect(self.start_detection)\n",
    "        self.buttons_layout.addWidget(self.start_button)\n",
    "\n",
    "        self.stop_button = QPushButton(\"Arr\\u00eater\")\n",
    "        self.stop_button.setStyleSheet(\"background-color: #dc3545; color: white;\")\n",
    "        self.stop_button.clicked.connect(self.stop_detection)\n",
    "        self.buttons_layout.addWidget(self.stop_button)\n",
    "\n",
    "        self.quit_button = QPushButton(\"Quitter\")\n",
    "        self.quit_button.setStyleSheet(\"background-color: #6c757d; color: white;\")\n",
    "        self.quit_button.clicked.connect(self.close)\n",
    "        self.buttons_layout.addWidget(self.quit_button)\n",
    "\n",
    "        self.layout.addLayout(self.buttons_layout)\n",
    "\n",
    "        # Configuration de la fenêtre\n",
    "        self.setLayout(self.layout)\n",
    "\n",
    "        # Timer pour mettre à jour la vidéo\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "\n",
    "        # Capture vidéo\n",
    "        self.cap = None\n",
    "\n",
    "        # Variables pour le mot en cours\n",
    "        self.current_word = \"\"\n",
    "        self.frame_counter = 0\n",
    "        self.last_letter = \"\"\n",
    "\n",
    "    def start_detection(self):\n",
    "        \"\"\"Démarrer la détection\"\"\"\n",
    "        if not self.cap:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "        self.timer.start(300)\n",
    "\n",
    "    def stop_detection(self):\n",
    "        \"\"\"Arrêter la détection\"\"\"\n",
    "        if self.cap:\n",
    "            self.timer.stop()\n",
    "            self.cap.release()\n",
    "            self.cap = None\n",
    "        self.video_label.clear()\n",
    "        self.character_label.setText(\"Caract\\u00e8re :\")\n",
    "        self.word_label.setText(\"Mot :\")\n",
    "        self.current_word = \"\"\n",
    "        self.frame_counter = 0\n",
    "\n",
    "    def update_frame(self):\n",
    "        \"\"\"Mettre à jour le flux vidéo et effectuer la classification\"\"\"\n",
    "        if self.cap and self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                # Afficher la vidéo\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                h, w, ch = rgb_frame.shape\n",
    "                bytes_per_line = ch * w\n",
    "                qimg = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "                self.video_label.setPixmap(QPixmap.fromImage(qimg))\n",
    "\n",
    "                # Effectuer la classification toutes les 20 images\n",
    "                self.frame_counter += 1\n",
    "                if self.frame_counter % 20 == 0:\n",
    "                    try:\n",
    "                        predicted_letter, confidence = classify_asl_frame(frame)\n",
    "                        if predicted_letter != self.last_letter:\n",
    "                            self.character_label.setText(f\"Caract\\u00e8re : {predicted_letter}\")\n",
    "                            self.current_word += predicted_letter\n",
    "                            self.word_label.setText(f\"Mot : {self.current_word}\")\n",
    "                            self.last_letter = predicted_letter\n",
    "                    except Exception as e:\n",
    "                        self.character_label.setText(f\"Erreur : {e}\")\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        \"\"\"Libérer les ressources à la fermeture\"\"\"\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        super().closeEvent(event)\n",
    "\n",
    "# Exécution de l'application\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = ASLApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea4908-1b72-43fd-8e4e-a464d60f6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "from PyQt5.QtCore import QTimer, Qt\n",
    "from PyQt5.QtGui import QImage, QPixmap, QFont\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QHBoxLayout, QPushButton, QWidget, QFrame\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Charger le modèle CNN\n",
    "model = load_model(\"sign_language_cnn_model2.h5\")\n",
    "class_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', \n",
    "                 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', \n",
    "                 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'del', \n",
    "                 27: 'nothing', 28: 'space'}\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"Convertit un cadre de la caméra en une image compatible avec le modèle CNN\"\"\"\n",
    "    resized_frame = cv2.resize(frame, (64, 64))\n",
    "    normalized_frame = resized_frame.astype('float32') / 255.0\n",
    "    input_frame = img_to_array(normalized_frame)\n",
    "    input_frame = np.expand_dims(input_frame, axis=0)  # Ajouter une dimension pour le batch\n",
    "    return input_frame\n",
    "\n",
    "def classify_asl_frame(frame):\n",
    "    \"\"\"Classifie un cadre pour détecter la lettre en langage des signes\"\"\"\n",
    "    input_frame = preprocess_frame(frame)\n",
    "    prediction = model.predict(input_frame)\n",
    "    predicted_class_idx = np.argmax(prediction)\n",
    "    confidence = np.max(prediction)\n",
    "    predicted_label = class_mapping[predicted_class_idx]\n",
    "    return predicted_label, confidence * 100\n",
    "\n",
    "class ASLApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Configuration de la fenêtre\n",
    "        self.setWindowTitle(\"Détection de la Langue des Signes\")\n",
    "        self.setGeometry(100, 100, 900, 700)\n",
    "        self.setStyleSheet(\"background-color: #1a1a1a; color: white;\")\n",
    "\n",
    "        # Layout principal\n",
    "        self.layout = QVBoxLayout()\n",
    "\n",
    "        # Titre\n",
    "        self.title_label = QLabel(\"D\\u00e9tection de la Langue des Signes\")\n",
    "        self.title_label.setAlignment(Qt.AlignCenter)\n",
    "        self.title_label.setFont(QFont(\"Arial\", 24, QFont.Bold))\n",
    "        self.title_label.setStyleSheet(\"color: white;\")\n",
    "        self.layout.addWidget(self.title_label)\n",
    "\n",
    "        # Layout pour la vidéo et les résultats\n",
    "        self.video_layout = QHBoxLayout()\n",
    "\n",
    "        # Affichage de la vidéo\n",
    "        self.video_label = QLabel()\n",
    "        self.video_label.setAlignment(Qt.AlignCenter)\n",
    "        self.video_label.setStyleSheet(\"background-color: #333;\")\n",
    "        self.video_layout.addWidget(self.video_label)\n",
    "\n",
    "        # Résultats\n",
    "        self.result_frame = QFrame()\n",
    "        self.result_frame.setStyleSheet(\"background-color: #2e2e2e; border: 1px solid #555;\")\n",
    "        self.result_layout = QVBoxLayout()\n",
    "\n",
    "        self.character_label = QLabel(\"Caract\\u00e8re :\")\n",
    "        self.character_label.setFont(QFont(\"Arial\", 18))\n",
    "        self.character_label.setAlignment(Qt.AlignCenter)\n",
    "        self.character_label.setStyleSheet(\"color: white;\")\n",
    "        self.result_layout.addWidget(self.character_label)\n",
    "\n",
    "        self.word_label = QLabel(\"Mot :\")\n",
    "        self.word_label.setFont(QFont(\"Arial\", 18))\n",
    "        self.word_label.setAlignment(Qt.AlignCenter)\n",
    "        self.word_label.setStyleSheet(\"color: white;\")\n",
    "        self.result_layout.addWidget(self.word_label)\n",
    "\n",
    "        self.result_frame.setLayout(self.result_layout)\n",
    "        self.video_layout.addWidget(self.result_frame)\n",
    "\n",
    "        self.layout.addLayout(self.video_layout)\n",
    "\n",
    "        # Boutons de contrôle\n",
    "        self.buttons_layout = QHBoxLayout()\n",
    "\n",
    "        self.start_button = QPushButton(\"D\\u00e9marrer\")\n",
    "        self.start_button.setStyleSheet(\"background-color: #007bff; color: white;\")\n",
    "        self.start_button.clicked.connect(self.start_detection)\n",
    "        self.buttons_layout.addWidget(self.start_button)\n",
    "\n",
    "        self.stop_button = QPushButton(\"Arr\\u00eater\")\n",
    "        self.stop_button.setStyleSheet(\"background-color: #dc3545; color: white;\")\n",
    "        self.stop_button.clicked.connect(self.stop_detection)\n",
    "        self.buttons_layout.addWidget(self.stop_button)\n",
    "\n",
    "        self.quit_button = QPushButton(\"Quitter\")\n",
    "        self.quit_button.setStyleSheet(\"background-color: #6c757d; color: white;\")\n",
    "        self.quit_button.clicked.connect(self.close)\n",
    "        self.buttons_layout.addWidget(self.quit_button)\n",
    "\n",
    "        self.layout.addLayout(self.buttons_layout)\n",
    "\n",
    "        # Configuration de la fenêtre\n",
    "        self.setLayout(self.layout)\n",
    "\n",
    "        # Timer pour mettre à jour la vidéo\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "\n",
    "        # Capture vidéo\n",
    "        self.cap = None\n",
    "\n",
    "        # Variables pour le mot en cours\n",
    "        self.current_word = \"\"\n",
    "        self.frame_counter = 0\n",
    "        self.last_letter = \"\"\n",
    "\n",
    "    def start_detection(self):\n",
    "        \"\"\"Démarrer la détection\"\"\"\n",
    "        if not self.cap:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "        self.timer.start(300)\n",
    "\n",
    "    def stop_detection(self):\n",
    "        \"\"\"Arrêter la détection\"\"\"\n",
    "        if self.cap:\n",
    "            self.timer.stop()\n",
    "            self.cap.release()\n",
    "            self.cap = None\n",
    "        self.video_label.clear()\n",
    "        self.character_label.setText(\"Caract\\u00e8re :\")\n",
    "        self.word_label.setText(\"Mot :\")\n",
    "        self.current_word = \"\"\n",
    "        self.frame_counter = 0\n",
    "\n",
    "    def update_frame(self):\n",
    "        \"\"\"Mettre à jour le flux vidéo et effectuer la classification\"\"\"\n",
    "        if self.cap and self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                # Afficher la vidéo\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                h, w, ch = rgb_frame.shape\n",
    "                bytes_per_line = ch * w\n",
    "                qimg = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "                self.video_label.setPixmap(QPixmap.fromImage(qimg))\n",
    "\n",
    "                # Effectuer la classification toutes les 20 images\n",
    "                self.frame_counter += 1\n",
    "                if self.frame_counter % 20 == 0:\n",
    "                    try:\n",
    "                        predicted_letter, confidence = classify_asl_frame(frame)\n",
    "                        if predicted_letter != self.last_letter:\n",
    "                            self.character_label.setText(f\"Caract\\u00e8re : {predicted_letter} ({confidence:.2f}%)\")\n",
    "                            self.current_word += predicted_letter\n",
    "                            self.word_label.setText(f\"Mot : {self.current_word}\")\n",
    "                            self.last_letter = predicted_letter\n",
    "                    except Exception as e:\n",
    "                        self.character_label.setText(f\"Erreur : {e}\")\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        \"\"\"Libérer les ressources à la fermeture\"\"\"\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        super().closeEvent(event)\n",
    "\n",
    "# Exécution de l'application\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = ASLApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
